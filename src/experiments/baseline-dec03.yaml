
############################# General Settings ################################
DPATH:      'data/'
RESULT:   &result 'results/baseline/dec03'
EXP_NAME: &exp 24h-skip

############################# Data Settings ###################################
VARIABLE:
  SAMPLE_RATE: &sample_rate 1d #1h|2h|3h|1d?
  INCLUDE_DATA: &in_data [physiology, activity] #physiology, activity, sleep, demographics
  TARGET_VAR: &target [Agitation]
  TEST_DAYS: &testdays 7d   #number of days from the end to make test data
  WINDOW_SIZE: &window 7    #number of sampled data to make one instance
  BATCH_SIZE: &bs 128       #number of sample to make a batch
  WEIGHT_SAMPLE: &sw true   #weight each sample by its prior belief
  REFIT_AFTER: &refit true  #refit model to entire train + valid dataset

############################# Experimetn Settings #############################
TRAIN_SPLIT:
  test_ratio: 0.3 
  test_window: *testdays
  by: patient
  
TEST_SPLIT:
  n_fold: 5
  test_window: *testdays   
  roll_window:  *window
  normalize_type: global #global or by id
  sample_rate: *sample_rate
  look_ahead: 0 #sample rate (detect vs predict?)
  use_cache: 'results/baseline'
  data_cache_path: '{data_cache_dir}/cached/{prefix}-{self.result_name}-f{fold}-l{look_ahead}-n{normalize_type[0]}-r{roll_window}-s{self.sample_rate}-t{test_window}.job'


SEED:       [42]
LOGGING:    reset     # append|reset

MODEL_SELECTION:
  mode: &mode min
  metric: &metric valid_loss

DL:
  Data:
    target_var: *target
    include_data: *in_data
    sample_rate: 1d

  Train:
    epoch: &epoch 100
    lr: &lr [1e-4,5e-4,1e-3]
    num_class: &nclass 2
    device: &gpu 1
    patience: [10]
    metric: *metric
    mode: *mode
    weight_sample: *sw
    batch_size: *bs
    refit: *refit

ML:
  Data:
    target_var: *target
    include_data: *in_data

  Train:
    weight_sample: *sw
    refit: *refit

# skip training and testing (match their running name + extraname)
SKIP_TRAIN: [MLP]
SKIP_TEST:  [MLP]

# how to aggregate final train-val-test result and report in paper
REPORT:
  group_column: ['model', 'stage']
  exclude_column: ['fold', 'seed']
  select_query: 'stage != "valid"'

RUNS:

  - name: MLP
    extra_name: ""
    hidden_layer_sizes: [[128,128], [26,26]]
    max_iter: [300]
    activation: ['tanh']
    alpha: [1e-3]
    early_stopping: [true]
    save_intermediate: true

  - name: LSTM
    hidden_size: [64]
    dropout: [0.0]
    num_layers: [1]
    bidirectional: [false]
    save_intermediate: true

  - name: GBM
    n_estimators: [20]
    min_samples_leaf: [1]
